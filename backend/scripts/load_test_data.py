#!/usr/bin/env python3
"""
è‹±å˜èªãƒã‚¹ã‚¿JSONLã‹ã‚‰DBæŠ•å…¥ï¼†ã‚¯ã‚¤ã‚ºè‡ªå‹•ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ã„æ–¹:
    docker compose exec backend python backend/scripts/load_test_data.py

æ©Ÿèƒ½:
    1. å˜èªãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«.json (JSONLå½¢å¼) ã‹ã‚‰èªå½™ãƒ‡ãƒ¼ã‚¿ã‚’DBã«æŠ•å…¥
    2. é‡è¦åº¦é †ã«ã‚¯ã‚¤ã‚ºæ§‹é€ ï¼ˆãƒ¬ãƒ™ãƒ«ãƒ»ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ»å•é¡Œï¼‰ã‚’è‡ªå‹•ç”Ÿæˆ
"""

import os
import sys
import json
from pathlib import Path

# Djangoè¨­å®š
sys.path.append('/app')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'quiz_backend.settings')

import django
django.setup()

from django.utils import timezone
from quiz.models import (
    Vocabulary, VocabTranslation, VocabChoice,
    VocabVisibility, VocabStatus,
    QuizCollection, Quiz, QuizQuestion, QuizScope,
)

# ---------------------------------------------------------------------------
# å®šæ•°è¨­å®š
# ---------------------------------------------------------------------------

ROOT_DIR = Path(__file__).resolve().parents[2]
JSONL_PATH = ROOT_DIR / "å˜èªãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«.json"

WORDS_PER_SECTION = 10       # 1ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å•é¡Œæ•°
SECTIONS_PER_LEVEL = 10       # 1ãƒ¬ãƒ™ãƒ«ã‚ãŸã‚Šã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°
RESET_EXISTING_DEFAULT_QUIZZES = False  # True ã«ã™ã‚‹ã¨æ—¢å­˜ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¯ã‚¤ã‚ºå‰Šé™¤

# ---------------------------------------------------------------------------
# Step 1: JSONLèª­ã¿è¾¼ã¿ï¼ˆé †åºç¶­æŒ & importanceæŠ½å‡ºï¼‰
# ---------------------------------------------------------------------------

def load_jsonl_with_importance():
    """
    JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€è¡Œé †ã‚’ä¿æŒã—ã¤ã¤importanceã‚’æŠ½å‡º
    
    æˆ»ã‚Šå€¤:
        records: [{ "line_no": int, "data": dict, "importance": int }, ...]
        importance_map: { text_en: importance, ... }
    """
    records = []
    importance_map = {}
    
    if not JSONL_PATH.exists():
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {JSONL_PATH}")
        return records, importance_map
    
    print(f"ğŸ“– JSONLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­: {JSONL_PATH}")
    
    with open(JSONL_PATH, 'r', encoding='utf-8') as f:
        for line_no, line in enumerate(f, start=1):
            line = line.strip()
            if not line:
                continue
            
            try:
                data = json.loads(line)
                text_en = data.get('text_en', '').strip()
                
                if not text_en:
                    print(f"âš ï¸  è¡Œ {line_no}: text_en ãŒç©ºã§ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                    continue
                
                # importance ã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 0ï¼‰
                importance = 0
                meta = data.get('meta', {})
                if isinstance(meta, dict):
                    try:
                        importance = int(meta.get('importance', 0))
                    except (ValueError, TypeError):
                        importance = 0
                
                records.append({
                    "line_no": line_no,
                    "data": data,
                    "importance": importance,
                })
                importance_map[text_en] = importance
                
            except json.JSONDecodeError as e:
                print(f"âš ï¸  è¡Œ {line_no}: JSONè§£æã‚¨ãƒ©ãƒ¼ - {e}")
                continue
    
    print(f"âœ… {len(records)} ä»¶ã®å˜èªã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    return records, importance_map

# ---------------------------------------------------------------------------
# Step 2: Vocabulary ç­‰ã® upsert
# ---------------------------------------------------------------------------

def upsert_vocab_from_records(records):
    """
    records ã‚’å…ˆé ­ã‹ã‚‰é †ç•ªã«å‡¦ç†ã—ã¦ Vocabulary/VocabTranslation/VocabChoice ã‚’ä½œæˆãƒ»æ›´æ–°
    
    æˆ»ã‚Šå€¤:
        vocab_list: upsertå¾Œã® Vocabulary ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆï¼ˆé †åºã¯ JSONè¡Œé †ï¼‰
    """
    vocab_list = []
    vocab_id_set = set()  # é‡è¤‡é˜²æ­¢
    
    # æ—¢å­˜ã® Vocabulary ã‚’ text_en ã§ãƒãƒƒãƒ”ãƒ³ã‚°
    existing_vocab_map = {
        v.text_en: v for v in Vocabulary.objects.all()
    }
    
    created_vocab = 0
    updated_vocab = 0
    created_trans = 0
    created_choice = 0
    
    now = timezone.now()
    
    print("\nğŸ“ èªå½™ãƒ‡ãƒ¼ã‚¿ã‚’DBã«æŠ•å…¥ä¸­...")
    
    for rec in records:
        data = rec['data']
        line_no = rec['line_no']
        
        text_en = data.get('text_en', '').strip()
        if not text_en:
            continue
        
        # Vocabulary ã®å–å¾—ã¾ãŸã¯ä½œæˆ
        vocab = existing_vocab_map.get(text_en)
        if vocab:
            # æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ã®æ›´æ–°
            updated = False
            
            # å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒéç©ºã®å ´åˆã®ã¿ä¸Šæ›¸ã
            if data.get('part_of_speech'):
                vocab.part_of_speech = data['part_of_speech']
                updated = True
            if data.get('explanation'):
                vocab.explanation = data['explanation']
                updated = True
            if data.get('example_en'):
                vocab.example_en = data['example_en']
                updated = True
            if data.get('example_ja'):
                vocab.example_ja = data['example_ja']
                updated = True
            
            # visibility / status / published_at ã‚’æ•´åˆ
            if vocab.visibility != VocabVisibility.PUBLIC:
                vocab.visibility = VocabVisibility.PUBLIC
                updated = True
            if vocab.status != VocabStatus.PUBLISHED:
                vocab.status = VocabStatus.PUBLISHED
                updated = True
            if vocab.published_at is None:
                vocab.published_at = now
                updated = True
            
            # sense_count ã‚’æ›´æ–°
            translations = data.get('translations', [])
            sense_count = max(1, len(translations))
            if vocab.sense_count != sense_count:
                vocab.sense_count = sense_count
                updated = True
            
            if updated:
                vocab.save()
                updated_vocab += 1
        else:
            # æ–°è¦ä½œæˆ
            translations = data.get('translations', [])
            vocab = Vocabulary.objects.create(
                text_en=text_en,
                part_of_speech=data.get('part_of_speech', ''),
                explanation=data.get('explanation', ''),
                example_en=data.get('example_en', ''),
                example_ja=data.get('example_ja', ''),
                sense_count=max(1, len(translations)),
                visibility=VocabVisibility.PUBLIC,
                status=VocabStatus.PUBLISHED,
                published_at=now,
            )
            existing_vocab_map[text_en] = vocab
            created_vocab += 1
        
        # vocab_list ã«è¿½åŠ ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
        if vocab.id not in vocab_id_set:
            vocab_list.append(vocab)
            vocab_id_set.add(vocab.id)
        
        # VocabTranslation ã®å‡¦ç†
        translations = data.get('translations', [])
        for idx, text_ja in enumerate(translations):
            if not text_ja.strip():
                continue
            
            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            existing_trans = VocabTranslation.objects.filter(
                vocabulary=vocab,
                text_ja=text_ja
            ).first()
            
            if not existing_trans:
                # primary ã‹ã©ã†ã‹ã®åˆ¤å®š
                has_primary = VocabTranslation.objects.filter(
                    vocabulary=vocab,
                    is_primary=True
                ).exists()
                
                is_primary = (idx == 0 and not has_primary)
                
                VocabTranslation.objects.create(
                    vocabulary=vocab,
                    text_ja=text_ja,
                    is_primary=is_primary,
                )
                created_trans += 1
            else:
                # æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã€primary ãŒæœªè¨­å®šã®å ´åˆ
                if idx == 0 and not existing_trans.is_primary:
                    if not VocabTranslation.objects.filter(vocabulary=vocab, is_primary=True).exists():
                        existing_trans.is_primary = True
                        existing_trans.save()
        
        # VocabChoice ã®å‡¦ç†
        choices = data.get('choices', {})
        correct_list = choices.get('correct', [])
        dummies_list = choices.get('dummies', [])
        
        for text_ja in correct_list:
            if not text_ja.strip():
                continue
            
            choice, choice_created = VocabChoice.objects.get_or_create(
                vocabulary=vocab,
                text_ja=text_ja,
                defaults={'is_correct': True, 'weight': 1.0}
            )
            if choice_created:
                created_choice += 1
            elif not choice.is_correct:
                choice.is_correct = True
                choice.save()
        
        for text_ja in dummies_list:
            if not text_ja.strip():
                continue
            
            choice, choice_created = VocabChoice.objects.get_or_create(
                vocabulary=vocab,
                text_ja=text_ja,
                defaults={'is_correct': False, 'weight': 0.5}
            )
            if choice_created:
                created_choice += 1
            elif choice.is_correct:
                choice.is_correct = False
                choice.save()
    
    print(f"âœ… èªå½™æŠ•å…¥å®Œäº†:")
    print(f"   æ–°è¦ä½œæˆ: {created_vocab} ä»¶")
    print(f"   æ›´æ–°: {updated_vocab} ä»¶")
    print(f"   ç¿»è¨³ä½œæˆ: {created_trans} ä»¶")
    print(f"   é¸æŠè‚¢ä½œæˆ: {created_choice} ä»¶")
    
    return vocab_list

# ---------------------------------------------------------------------------
# Step 3: ã‚¯ã‚¤ã‚ºæ§‹é€ ç”Ÿæˆ
# ---------------------------------------------------------------------------

def build_quizzes_from_vocab(vocab_list, importance_map):
    """
    vocab_list ã‚’ importance é †ã«ã‚½ãƒ¼ãƒˆã—ã€ã‚¯ã‚¤ã‚ºæ§‹é€ ã‚’è‡ªå‹•ç”Ÿæˆ
    """
    # æ—¢å­˜ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¯ã‚¤ã‚ºã®å‰Šé™¤ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    if RESET_EXISTING_DEFAULT_QUIZZES:
        print("\nğŸ—‘ï¸  æ—¢å­˜ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¯ã‚¤ã‚ºã‚’å‰Šé™¤ä¸­...")
        QuizQuestion.objects.filter(quiz__quiz_collection__scope=QuizScope.DEFAULT).delete()
        Quiz.objects.filter(quiz_collection__scope=QuizScope.DEFAULT).delete()
        QuizCollection.objects.filter(scope=QuizScope.DEFAULT).delete()
        print("âœ… å‰Šé™¤å®Œäº†")
    
    # importance é™é †ã§ã‚½ãƒ¼ãƒˆ
    sorted_vocab = sorted(
        vocab_list,
        key=lambda v: (-importance_map.get(v.text_en, 0), v.text_en),
    )
    
    print(f"\nğŸ¯ ã‚¯ã‚¤ã‚ºæ§‹é€ ã‚’ç”Ÿæˆä¸­ï¼ˆå…¨ {len(sorted_vocab)} å˜èªï¼‰...")
    
    now = timezone.now()
    level_set = set()
    section_set = set()
    question_count = 0
    
    for idx, vocab in enumerate(sorted_vocab):
        # ãƒ¬ãƒ™ãƒ«ãƒ»ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ»å•é¡Œç•ªå·ã®è¨ˆç®—
        level_idx = idx // (WORDS_PER_SECTION * SECTIONS_PER_LEVEL)
        level_no = level_idx + 1

        section_idx = (idx // WORDS_PER_SECTION) % SECTIONS_PER_LEVEL
        section_no = section_idx + 1

        question_order = (idx % WORDS_PER_SECTION) + 1
        
        # QuizCollection (ãƒ¬ãƒ™ãƒ«) ã®å–å¾—ã¾ãŸã¯ä½œæˆ
        level_code = f"L{level_no}"
        qc, qc_created = QuizCollection.objects.get_or_create(
            scope=QuizScope.DEFAULT,
            level_code=level_code,
            defaults={
                'title': f"ãƒ¬ãƒ™ãƒ«{level_no}",
                'description': f"é‡è¦åº¦é † è‹±å˜èªãƒ¬ãƒ™ãƒ«{level_no}",
                'level_label': f"ãƒ¬ãƒ™ãƒ«{level_no}",
                'level_order': level_no,
                'order_index': level_no,
                'is_published': True,
                'published_at': now,
            }
        )
        level_set.add(level_no)
        
        # Quiz (ã‚»ã‚¯ã‚·ãƒ§ãƒ³) ã®å–å¾—ã¾ãŸã¯ä½œæˆ
        quiz, quiz_created = Quiz.objects.get_or_create(
            quiz_collection=qc,
            sequence_no=section_no,
            defaults={
                'title': f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³{section_no}",
                'section_no': section_no,
                'section_label': f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³{section_no}",
                'timer_seconds': 10,
            }
        )
        if not quiz_created:
            updated = False
            desired_title = f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³{section_no}"
            desired_label = f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³{section_no}"
            if quiz.title != desired_title:
                quiz.title = desired_title
                updated = True
            if quiz.section_label != desired_label:
                quiz.section_label = desired_label
                updated = True
            if quiz.section_no != section_no:
                quiz.section_no = section_no
                updated = True
            if quiz.timer_seconds is None:
                quiz.timer_seconds = 10
                updated = True
            if updated:
                quiz.save(update_fields=["title", "section_label", "section_no", "timer_seconds", "updated_at"])
        section_set.add((level_no, section_no))
        
        # QuizQuestion (å•é¡Œ) ã®ä½œæˆã¾ãŸã¯æ›´æ–°
        QuizQuestion.objects.update_or_create(
            quiz=quiz,
            question_order=question_order,
            defaults={
                'vocabulary': vocab,
                'note': '',
            }
        )
        question_count += 1
    
    print(f"âœ… ã‚¯ã‚¤ã‚ºç”Ÿæˆå®Œäº†:")
    print(f"   ãƒ¬ãƒ™ãƒ«æ•°: {len(level_set)}")
    print(f"   ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(section_set)}")
    print(f"   ç·å•é¡Œæ•°: {question_count}")

# ---------------------------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
# ---------------------------------------------------------------------------

def run():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("è‹±å˜èªãƒã‚¹ã‚¿JSONL â†’ DBæŠ•å…¥ ï¼† ã‚¯ã‚¤ã‚ºè‡ªå‹•ç”Ÿæˆ")
    print("=" * 60)
    
    # Step 1: JSONLèª­ã¿è¾¼ã¿
    records, importance_map = load_jsonl_with_importance()
    if not records:
        print("âŒ èª­ã¿è¾¼ã‚€ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return
    
    # Step 2: Vocabulary ç­‰ã® upsert
    vocab_list = upsert_vocab_from_records(records)
    
    # Step 3: ã‚¯ã‚¤ã‚ºæ§‹é€ ç”Ÿæˆ
    build_quizzes_from_vocab(vocab_list, importance_map)
    
    # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    print("\n" + "=" * 60)
    print("ğŸ“Š æœ€çµ‚çµ±è¨ˆ")
    print("=" * 60)
    print(f"Total Vocabularies: {Vocabulary.objects.count()}")
    print(f"Total Translations: {VocabTranslation.objects.count()}")
    print(f"Total Choices: {VocabChoice.objects.count()}")
    print(f"Total QuizCollections: {QuizCollection.objects.count()}")
    print(f"Total Quizzes: {Quiz.objects.count()}")
    print(f"Total QuizQuestions: {QuizQuestion.objects.count()}")
    print("=" * 60)
    print("âœ¨ å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == '__main__':
    run()
